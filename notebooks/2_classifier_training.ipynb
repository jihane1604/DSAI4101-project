{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7a4089-3612-4f6c-97ea-cf00825ab947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd5ca73-09c6-4aa8-9c11-9f02dd5ace5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0499a9b-3e21-4055-b07e-f7f9e95cba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Improved CNN:\n",
    "    - ResNet18 backbone (fully fine-tuned)\n",
    "    - 256-dim embedding for anomaly detection\n",
    "    - 6-class classifier head\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int = 6, embed_dim: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(512, embed_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        \"\"\"\n",
    "        Return embedding vector (B, embed_dim).\n",
    "        Use this for anomaly detection later.\n",
    "        \"\"\"\n",
    "        x = self.feature_extractor(x)   \n",
    "        x = torch.flatten(x, 1)       \n",
    "        x = self.embedding(x)       \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.forward_features(x)     \n",
    "        logits = self.classifier(feats)      \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27250347-0899-4f74-bcf6-f6d62d68b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Train size: 1767\n",
      "Val size  : 377\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "train_dir = Path(\"../data/split/train\")\n",
    "val_dir   = Path(\"../data/split/val\")\n",
    "\n",
    "# ---- Stronger augmentations for better generalization ----\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
    "val_dataset   = datasets.ImageFolder(val_dir,   transform=val_tfms)\n",
    "\n",
    "batch_size = 32  # reduce to 16 if RAM is angry\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Val size  :\", len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7541c226-700b-414d-8052-400b765863e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/8] Train: Loss=1.1660 Acc=0.5823 | Val: Loss=0.6147 Acc=0.7639\n",
      "Epoch [2/8] Train: Loss=0.5919 Acc=0.8087 | Val: Loss=0.4132 Acc=0.8647\n",
      "Epoch [3/8] Train: Loss=0.3965 Acc=0.8721 | Val: Loss=0.4806 Acc=0.8223\n",
      "Epoch [4/8] Train: Loss=0.3088 Acc=0.8993 | Val: Loss=0.2937 Acc=0.8992\n",
      "Epoch [5/8] Train: Loss=0.2410 Acc=0.9208 | Val: Loss=0.3348 Acc=0.8912\n",
      "Epoch [6/8] Train: Loss=0.2211 Acc=0.9304 | Val: Loss=0.2757 Acc=0.9098\n",
      "Epoch [7/8] Train: Loss=0.1541 Acc=0.9502 | Val: Loss=0.2797 Acc=0.9072\n",
      "Epoch [8/8] Train: Loss=0.1176 Acc=0.9626 | Val: Loss=0.2705 Acc=0.8992\n",
      "\n",
      "==== DONE ====\n",
      "Best validation accuracy: 0.9098143236074271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Model (full fine-tuning, nothing frozen) ----\n",
    "model = SimpleCNN(num_classes=6, embed_dim=256).to(device)\n",
    "\n",
    "# All params trainable now\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,          # lower LR because we fine-tune whole backbone\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 8        \n",
    "best_val_acc = 0.0\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc  = correct / total\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss_total = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss_total += loss.item() * imgs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_loss = val_loss_total / val_total\n",
    "    val_acc  = val_correct / val_total\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{num_epochs}] \"\n",
    "        f\"Train: Loss={train_loss:.4f} Acc={train_acc:.4f} | \"\n",
    "        f\"Val: Loss={val_loss:.4f} Acc={val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Keep best weights IN MEMORY ONLY\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state_dict = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "print(\"\\n==== DONE ====\")\n",
    "print(\"Best validation accuracy:\", best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92534d90-0218-4889-9b67-cfd68de9f334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook running from: C:\\Users\\sadek\\OneDrive\\Desktop\\DSAI4101-project\\notebooks\n",
      "Saved model weights to: ..\\models\\classifier\\simple_cnn.pth\n",
      "Saved class names to: ..\\models\\classifier\\classes.json\n",
      "Classes: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"Notebook running from:\", os.getcwd())\n",
    "\n",
    "# go one level up from notebooks/ â†’ project root\n",
    "save_dir = Path(\"../models/classifier\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2) Save model weights (current model)\n",
    "model_path = save_dir / \"simple_cnn.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Saved model weights to: {model_path}\")\n",
    "\n",
    "# 3) Save class names\n",
    "class_names = train_dataset.classes\n",
    "classes_path = save_dir / \"classes.json\"\n",
    "with open(classes_path, \"w\") as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "print(f\"Saved class names to: {classes_path}\")\n",
    "print(\"Classes:\", class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
