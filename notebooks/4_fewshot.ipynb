{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f30621-6105-491c-b0bb-8c3f236b9d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: C:\\Users\\sadek\\OneDrive\\Desktop\\DSAI4101-project\n",
      "Current working directory: C:\\Users\\sadek\\OneDrive\\Desktop\\DSAI4101-project\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up one level: from notebooks/ â†’ project root\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Added to sys.path:\", project_root)\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f549d1-453d-44b5-8d8e-a42d41335abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Classes: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from src.b_models_impl import MyEmbeddingClient  \n",
    "\n",
    "emb_client = MyEmbeddingClient(\n",
    "    model_path=\"../models/classifier/simple_cnn.pth\",\n",
    "    classes_path=\"../models/classifier/classes.json\"\n",
    ")\n",
    "\n",
    "device = emb_client.device\n",
    "model = emb_client.model\n",
    "model.eval()\n",
    "\n",
    "print(\"Device:\", device)\n",
    "print(\"Classes:\", emb_client.idx_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2bc9db7-ed2a-479a-9e8f-cb289f2d1f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot classes: ['clothes', 'electronics', 'food', 'toys']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "fewshot_root = Path(\"../data/rare_fewshot\")   # clothes/electronics/etc.\n",
    "transform = emb_client.transform              # SAME transform as classifier/anomaly\n",
    "\n",
    "fewshot_ds = datasets.ImageFolder(str(fewshot_root), transform=transform)\n",
    "fewshot_loader = DataLoader(fewshot_ds, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"Few-shot classes:\", fewshot_ds.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91e3c3cb-270d-4a58-b205-d3d0be297140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothes -> 12 embeddings\n",
      "electronics -> 8 embeddings\n",
      "food -> 13 embeddings\n",
      "toys -> 7 embeddings\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "embs_per_class = {i: [] for i in range(len(fewshot_ds.classes))}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in fewshot_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        feats = model.forward_features(imgs).cpu().numpy()  # (B, 256)\n",
    "        \n",
    "        for f, lbl in zip(feats, labels.numpy()):\n",
    "            embs_per_class[int(lbl)].append(f)\n",
    "\n",
    "for k, v in embs_per_class.items():\n",
    "    print(f\"{fewshot_ds.classes[k]} -> {len(v)} embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a074b02-e114-43e6-bacd-5a731fb1964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built prototypes for: ['clothes', 'electronics', 'food', 'toys']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "prototypes = {}\n",
    "for cls_idx, embs in embs_per_class.items():\n",
    "    arr = np.stack(embs, axis=0)              # (N, 256)\n",
    "    proto = arr.mean(axis=0)                  # (256,)\n",
    "    proto = proto / (np.linalg.norm(proto) + 1e-8)  # normalize\n",
    "    prototypes[cls_idx] = proto\n",
    "\n",
    "print(\"Built prototypes for:\", fewshot_ds.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ca166ae-b4a9-4506-a3e5-54be7e28e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proto_mat shape: (4, 256)\n",
      "Class names: ['clothes', 'electronics', 'food', 'toys']\n"
     ]
    }
   ],
   "source": [
    "# Build prototype matrix & label list once\n",
    "proto_mat = np.stack([prototypes[i] for i in sorted(prototypes.keys())], axis=0)  # (C, 256)\n",
    "proto_labels = [i for i in sorted(prototypes.keys())]\n",
    "class_names = fewshot_ds.classes\n",
    "\n",
    "print(\"Proto_mat shape:\", proto_mat.shape)\n",
    "print(\"Class names:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6564bc0-433d-4637-81ce-e0f54c51a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_predict_from_imgs(imgs, unknown_threshold=0.4):\n",
    "    \"\"\"\n",
    "    imgs: torch Tensor (B, C, H, W) already transformed\n",
    "    returns: list of dicts {label, confidence, similarity}\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        feats = model.forward_features(imgs.to(device)).cpu().numpy()  # (B, 256)\n",
    "\n",
    "    # normalize embeddings\n",
    "    X_norm = feats / (np.linalg.norm(feats, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "    # cosine similarity = dot product (since normalized)\n",
    "    sims = X_norm @ proto_mat.T   # (B, C)\n",
    "\n",
    "    results = []\n",
    "    for i in range(X_norm.shape[0]):\n",
    "        sim_vec = sims[i]\n",
    "        best_idx = int(np.argmax(sim_vec))\n",
    "        best_sim = float(sim_vec[best_idx])\n",
    "        cls_idx  = proto_labels[best_idx]\n",
    "        cls_name = class_names[cls_idx]\n",
    "\n",
    "        # simple confidence scaled to [0,1]\n",
    "        confidence = (best_sim + 1) / 2.0\n",
    "\n",
    "        if best_sim < unknown_threshold:\n",
    "            label = \"unknown\"\n",
    "        else:\n",
    "            label = cls_name\n",
    "\n",
    "        results.append({\n",
    "            \"label\": label,\n",
    "            \"confidence\": confidence,\n",
    "            \"similarity\": best_sim\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b25734c9-0abf-4ef6-ba31-74a9d263a912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: clothes  ->  Pred: {'label': 'clothes', 'confidence': 0.9727566838264465, 'similarity': 0.9455133676528931}\n",
      "True: clothes  ->  Pred: {'label': 'clothes', 'confidence': 0.9758226275444031, 'similarity': 0.9516452550888062}\n",
      "True: clothes  ->  Pred: {'label': 'clothes', 'confidence': 0.9587733745574951, 'similarity': 0.9175467491149902}\n",
      "True: clothes  ->  Pred: {'label': 'clothes', 'confidence': 0.977133572101593, 'similarity': 0.954267144203186}\n",
      "True: clothes  ->  Pred: {'label': 'clothes', 'confidence': 0.9672718942165375, 'similarity': 0.934543788433075}\n",
      "True: clothes  ->  Pred: {'label': 'clothes', 'confidence': 0.9715071022510529, 'similarity': 0.9430142045021057}\n",
      "True: clothes  ->  Pred: {'label': 'electronics', 'confidence': 0.952756941318512, 'similarity': 0.9055138826370239}\n",
      "True: clothes  ->  Pred: {'label': 'unknown', 'confidence': 0.9479445219039917, 'similarity': 0.8958890438079834}\n",
      "True: clothes  ->  Pred: {'label': 'unknown', 'confidence': 0.9306397438049316, 'similarity': 0.8612794876098633}\n",
      "True: clothes  ->  Pred: {'label': 'clothes', 'confidence': 0.9596155285835266, 'similarity': 0.9192310571670532}\n",
      "True: clothes  ->  Pred: {'label': 'unknown', 'confidence': 0.912513792514801, 'similarity': 0.825027585029602}\n",
      "True: clothes  ->  Pred: {'label': 'clothes', 'confidence': 0.9630325436592102, 'similarity': 0.9260650873184204}\n",
      "True: electronics  ->  Pred: {'label': 'unknown', 'confidence': 0.9403356909751892, 'similarity': 0.8806713819503784}\n",
      "True: electronics  ->  Pred: {'label': 'electronics', 'confidence': 0.9596699476242065, 'similarity': 0.9193398952484131}\n",
      "True: electronics  ->  Pred: {'label': 'clothes', 'confidence': 0.9526625871658325, 'similarity': 0.905325174331665}\n",
      "True: electronics  ->  Pred: {'label': 'unknown', 'confidence': 0.9023589789867401, 'similarity': 0.8047179579734802}\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# take first few images from the few-shot loader\n",
    "imgs_batch, labels_batch = next(iter(fewshot_loader))\n",
    "\n",
    "outs = fewshot_predict_from_imgs(imgs_batch, unknown_threshold=0.90)\n",
    "\n",
    "for i, o in enumerate(outs):\n",
    "    true_label = class_names[labels_batch[i].item()]\n",
    "    print(f\"True: {true_label}  ->  Pred:\", o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a900c926-e690-494b-b55c-d480ecb3e3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved few-shot prototypes to: ../models/fewshot\\prototypes.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create folder if missing\n",
    "save_dir = \"../models/fewshot\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save everything Person A needs\n",
    "save_path = os.path.join(save_dir, \"prototypes.pkl\")\n",
    "\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"prototypes\": prototypes,          # dict: {class_idx: vector}\n",
    "        \"class_names\": class_names,        # list of names\n",
    "        \"unknown_threshold\": 0.92          # your chosen threshold\n",
    "    },\n",
    "    save_path\n",
    ")\n",
    "\n",
    "print(\"Saved few-shot prototypes to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fc5cd57-ffa7-4187-b27e-b49af2040992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-shot accuracy (excluding unknown cases): 0.6923076923076923\n",
      "Unknown rate: 0.675\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "unknown_count = 0\n",
    "\n",
    "for imgs, labels in fewshot_loader:\n",
    "    outs = fewshot_predict_from_imgs(imgs, unknown_threshold=0.92)\n",
    "    for i, o in enumerate(outs):\n",
    "        true_name = class_names[labels[i].item()]\n",
    "        pred_name = o[\"label\"]\n",
    "        total += 1\n",
    "        if pred_name == \"unknown\":\n",
    "            unknown_count += 1\n",
    "        if pred_name == true_name:\n",
    "            correct += 1\n",
    "\n",
    "print(\"Few-shot accuracy (excluding unknown cases):\", correct / (total - unknown_count))\n",
    "print(\"Unknown rate:\", unknown_count / total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
